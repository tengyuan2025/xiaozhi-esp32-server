import httpx
import openai
from openai.types import CompletionUsage
from config.logger import setup_logging
from core.utils.util import check_model_key
from core.providers.llm.base import LLMProviderBase

TAG = __name__
logger = setup_logging()


class LLMProvider(LLMProviderBase):
    def __init__(self, config):
        self.model_name = config.get("model_name")
        self.api_key = config.get("api_key")
        if "base_url" in config:
            self.base_url = config.get("base_url")
        else:
            self.base_url = config.get("url")
        # å¢åŠ timeoutçš„é…ç½®é¡¹ï¼Œå•ä½ä¸ºç§’
        timeout = config.get("timeout", 300)
        self.timeout = int(timeout) if timeout else 300

        # å¤„ç†é¢å¤–å‚æ•°
        self.extra_params = config.get("extra_params", {})

        param_defaults = {
            "max_tokens": (500, int),
            "temperature": (0.7, lambda x: round(float(x), 1)),
            "top_p": (1.0, lambda x: round(float(x), 1)),
            "frequency_penalty": (0, lambda x: round(float(x), 1)),
        }

        for param, (default, converter) in param_defaults.items():
            value = config.get(param)
            try:
                setattr(
                    self,
                    param,
                    converter(value) if value not in (None, "") else default,
                )
            except (ValueError, TypeError):
                setattr(self, param, default)

        logger.debug(
            f"æ„å›¾è¯†åˆ«å‚æ•°åˆå§‹åŒ–: {self.temperature}, {self.max_tokens}, {self.top_p}, {self.frequency_penalty}"
        )

        model_key_msg = check_model_key("LLM", self.api_key)
        if model_key_msg:
            logger.bind(tag=TAG).error(model_key_msg)
        
        # æ£€æŸ¥ä»£ç†è®¾ç½®å¹¶æ ¹æ®åŸŸåå†³å®šæ˜¯å¦ä½¿ç”¨ä»£ç†
        import os
        from urllib.parse import urlparse
        
        http_proxy = os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')
        https_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')
        
        # è§£æç›®æ ‡åŸŸå
        parsed_url = urlparse(self.base_url)
        domain = parsed_url.hostname
        
        # åªå¯¹claude.aiå’Œanthropic.comåŸŸåä½¿ç”¨ä»£ç†
        use_proxy = domain and (domain.endswith('claude.ai') or domain.endswith('anthropic.com'))
        
        logger.bind(tag=TAG).info(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ– - API Base URL: {self.base_url}")
        logger.bind(tag=TAG).info(f"ç›®æ ‡åŸŸå: {domain}, æ˜¯å¦ä½¿ç”¨ä»£ç†: {use_proxy}")
        logger.bind(tag=TAG).info(f"ç³»ç»Ÿç¯å¢ƒä»£ç†è®¾ç½® - HTTP_PROXY: {http_proxy}, HTTPS_PROXY: {https_proxy}")
        
        # æ ¹æ®åŸŸåå†³å®šæ˜¯å¦ä½¿ç”¨ä»£ç†
        if use_proxy:
            # ä½¿ç”¨ç³»ç»Ÿä»£ç†è®¾ç½®
            self.client = openai.OpenAI(api_key=self.api_key, base_url=self.base_url, timeout=httpx.Timeout(self.timeout))
            logger.bind(tag=TAG).info("ä½¿ç”¨ä»£ç†è¿æ¥")
        else:
            # å¼ºåˆ¶ä¸ä½¿ç”¨ä»£ç†
            http_client = httpx.Client(
                timeout=httpx.Timeout(self.timeout),
                proxies={
                    "http://": None,
                    "https://": None,
                    "all://": None
                },
                limits=httpx.Limits(max_keepalive_connections=10, max_connections=20),
                http2=True,
                verify=True
            )
            self.client = openai.OpenAI(
                api_key=self.api_key, 
                base_url=self.base_url, 
                http_client=http_client
            )
            logger.bind(tag=TAG).info("å¼ºåˆ¶ç›´è¿ï¼Œå®Œå…¨ç¦ç”¨ä»£ç†")
    
    def _filter_reasoning_content(self, text):
        """è¿‡æ»¤æ‰è±†åŒ…æ¨¡å‹çš„reasoningå†…å®¹ï¼Œåªä¿ç•™æœ€ç»ˆå›ç­”"""
        # è±†åŒ…çš„reasoningé€šå¸¸åŒ…å«æ¨ç†è¿‡ç¨‹ï¼Œæˆ‘ä»¬åªéœ€è¦æœ€ç»ˆçš„ç”¨æˆ·å›ç­”éƒ¨åˆ†
        # å¦‚æœåŒ…å«æ¨ç†æ ‡è®°ï¼Œå°è¯•æå–æœ€ç»ˆç­”æ¡ˆ
        if 'æ¨ç†' in text or 'å› ä¸º' in text or 'æ‰€ä»¥' in text:
            # ç®€å•å¯å‘å¼ï¼šå–æœ€åä¸€ä¸ªå¥å·ä¹‹åçš„å†…å®¹ï¼Œæˆ–è€…æœ€çŸ­çš„æœ‰æ„ä¹‰å›ç­”
            sentences = text.split('ã€‚')
            for i in range(len(sentences)-1, -1, -1):
                sentence = sentences[i].strip()
                if sentence and len(sentence) < 100 and not any(word in sentence for word in ['å› ä¸º', 'æ‰€ä»¥', 'æ¨ç†', 'åˆ†æ']):
                    return sentence + 'ã€‚' if not sentence.endswith('ã€‚') else sentence
        return text

    def response(self, session_id, dialogue, **kwargs):
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": self.model_name,
                "messages": dialogue,
                "stream": True,
                "max_tokens": kwargs.get("max_tokens", self.max_tokens),
                "temperature": kwargs.get("temperature", self.temperature),
                "top_p": kwargs.get("top_p", self.top_p),
                "frequency_penalty": kwargs.get(
                    "frequency_penalty", self.frequency_penalty
                ),
            }
            
            # æ·»åŠ é¢å¤–å‚æ•°
            request_params.update(self.extra_params)
            
            # æ‰“å°è¯·æ±‚URLå’Œå‚æ•°ï¼Œæ£€æŸ¥ç½‘ç»œè·¯å¾„
            logger.bind(tag=TAG).info(f"LLMè¯·æ±‚URL: {self.base_url}/chat/completions")
            logger.bind(tag=TAG).info(f"LLMè¯·æ±‚å‚æ•°: model={request_params['model']}, "
                                    f"max_tokens={request_params['max_tokens']}, "
                                    f"temperature={request_params['temperature']}, "
                                    f"messages_count={len(request_params['messages'])}")
            
            # æ£€æŸ¥httpxå®¢æˆ·ç«¯çš„ä»£ç†é…ç½®
            if hasattr(self.client._client, '_mounts'):
                logger.bind(tag=TAG).info(f"HTTPxå®¢æˆ·ç«¯é…ç½®: {self.client._client._mounts}")
            
            logger.bind(tag=TAG).debug(f"LLMå®Œæ•´è¯·æ±‚å‚æ•°: {request_params}")
            
            # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
            import time
            request_start = time.time()
            logger.bind(tag=TAG).info(f"å¼€å§‹å‘é€LLMè¯·æ±‚ - {request_start}")
            
            responses = self.client.chat.completions.create(**request_params)
            
            # è®°å½•é¦–ä¸ªå“åº”æ—¶é—´
            first_response_time = time.time()
            logger.bind(tag=TAG).info(f"æ”¶åˆ°é¦–ä¸ªå“åº” - è€—æ—¶: {first_response_time - request_start:.3f}ç§’")

            is_active = True
            full_response = ""  # æ”¶é›†å®Œæ•´å“åº”
            chunk_count = 0
            first_content_time = None
            
            for chunk in responses:
                chunk_count += 1
                chunk_time = time.time()
                
                try:
                    # è®°å½•åŸå§‹chunkæ•°æ®
                    logger.bind(tag=TAG).debug(f"LLMå“åº”chunk #{chunk_count} - æ—¶é—´: {chunk_time - request_start:.3f}s: {chunk}")
                    
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœ‰æ•ˆçš„choiceä¸”contentä¸ä¸ºç©º
                    delta = (
                        chunk.choices[0].delta
                        if getattr(chunk, "choices", None)
                        else None
                    )
                    content = delta.content if hasattr(delta, "content") else ""
                except IndexError:
                    content = ""
                
                if content and first_content_time is None:
                    first_content_time = chunk_time
                    logger.bind(tag=TAG).info(f"ğŸ¤– LLMé¦–æ¬¡å“åº” - è€—æ—¶: {first_content_time - request_start:.3f}ç§’")
                
                if content:
                    full_response += content  # ç´¯ç§¯å®Œæ•´å“åº”
                    
                    # è¿‡æ»¤è±†åŒ…çš„reasoningå†…å®¹
                    filtered_content = content
                    if "reasoning_content" in str(chunk):
                        # å¦‚æœchunkåŒ…å«reasoning_contentï¼Œè·³è¿‡è¿™éƒ¨åˆ†
                        logger.bind(tag=TAG).debug(f"æ£€æµ‹åˆ°reasoningå†…å®¹ï¼Œå·²è¿‡æ»¤")
                        continue
                    
                    # å¤„ç†æ ‡ç­¾è·¨å¤šä¸ªchunkçš„æƒ…å†µ
                    if "<think>" in filtered_content:
                        is_active = False
                        filtered_content = filtered_content.split("<think>")[0]
                    if "</think>" in filtered_content:
                        is_active = True
                        filtered_content = filtered_content.split("</think>")[-1]
                    
                    if is_active and filtered_content:
                        yield filtered_content
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_time = time.time() - request_start
            logger.bind(tag=TAG).info(f"LLMå“åº”ç»Ÿè®¡ - æ€»chunkæ•°: {chunk_count}, é¦–å“åº”: {first_response_time - request_start:.3f}s, é¦–å†…å®¹: {(first_content_time - request_start):.3f}s, æ€»è€—æ—¶: {total_time:.3f}s")
            
            # è¿‡æ»¤reasoningå†…å®¹å†è®°å½•
            filtered_response = self._filter_reasoning_content(full_response)
            logger.bind(tag=TAG).info(f"LLMå®Œæ•´å“åº”ï¼ˆå·²è¿‡æ»¤reasoningï¼‰: {filtered_response}")

        except Exception as e:
            logger.bind(tag=TAG).error(f"Error in response generation: {e}")

    def response_with_functions(self, session_id, dialogue, functions=None):
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": self.model_name,
                "messages": dialogue,
                "stream": True,
                "tools": functions
            }
            
            # æ‰“å°è¯·æ±‚URLå’Œå‚æ•°
            logger.bind(tag=TAG).info(f"LLMå‡½æ•°è°ƒç”¨è¯·æ±‚URL: {self.base_url}/chat/completions")
            logger.bind(tag=TAG).info(f"LLMå‡½æ•°è°ƒç”¨è¯·æ±‚å‚æ•°: model={request_params['model']}, "
                                    f"messages_count={len(request_params['messages'])}, "
                                    f"tools_count={len(functions) if functions else 0}")
            logger.bind(tag=TAG).debug(f"LLMå‡½æ•°è°ƒç”¨å®Œæ•´è¯·æ±‚å‚æ•°: {request_params}")
            
            # è®°å½•å‡½æ•°è°ƒç”¨è¯·æ±‚å¼€å§‹æ—¶é—´
            import time
            request_start = time.time()
            logger.bind(tag=TAG).info(f"å¼€å§‹å‘é€LLMå‡½æ•°è°ƒç”¨è¯·æ±‚ - {request_start}")
            
            stream = self.client.chat.completions.create(**request_params)
            
            # è®°å½•é¦–ä¸ªå“åº”æ—¶é—´
            first_response_time = time.time()
            logger.bind(tag=TAG).info(f"æ”¶åˆ°é¦–ä¸ªå‡½æ•°è°ƒç”¨å“åº” - è€—æ—¶: {first_response_time - request_start:.3f}ç§’")

            full_response = ""  # æ”¶é›†å®Œæ•´å“åº”
            function_calls = []  # æ”¶é›†å‡½æ•°è°ƒç”¨
            chunk_count = 0
            for chunk in stream:
                chunk_count += 1
                chunk_time = time.time()
                
                # åªè®°å½•æœ‰å†…å®¹çš„chunk
                logger.bind(tag=TAG).debug(f"LLMå‡½æ•°è°ƒç”¨å“åº”chunk #{chunk_count}: {chunk}")
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœ‰æ•ˆçš„choiceä¸”contentä¸ä¸ºç©º
                if getattr(chunk, "choices", None):
                    content = chunk.choices[0].delta.content
                    tool_calls = chunk.choices[0].delta.tool_calls
                    
                    if content:
                        full_response += content
                        if chunk_count <= 5 or len(content) > 1:  # åªè®°å½•å‰5ä¸ªæˆ–æœ‰æ„ä¹‰çš„å†…å®¹
                            logger.bind(tag=TAG).info(f"æ”¶åˆ°å†…å®¹chunk #{chunk_count}: '{content}' - {chunk_time - request_start:.3f}s")
                    if tool_calls:
                        function_calls.append(tool_calls)
                        logger.bind(tag=TAG).info(f"æ”¶åˆ°å·¥å…·è°ƒç”¨ #{chunk_count}: {tool_calls} - {chunk_time - request_start:.3f}s")
                    
                    yield content, tool_calls
                # å­˜åœ¨ CompletionUsage æ¶ˆæ¯æ—¶ï¼Œç”Ÿæˆ Token æ¶ˆè€— log
                elif isinstance(getattr(chunk, "usage", None), CompletionUsage):
                    usage_info = getattr(chunk, "usage", None)
                    logger.bind(tag=TAG).info(
                        f"Token æ¶ˆè€—ï¼ˆæ—¶é—´: {chunk_time - request_start:.3f}sï¼‰ï¼šè¾“å…¥ {getattr(usage_info, 'prompt_tokens', 'æœªçŸ¥')}ï¼Œ"
                        f"è¾“å‡º {getattr(usage_info, 'completion_tokens', 'æœªçŸ¥')}ï¼Œ"
                        f"å…±è®¡ {getattr(usage_info, 'total_tokens', 'æœªçŸ¥')}"
                    )
            
            # ç»Ÿè®¡å’Œæ‰“å°å®Œæ•´å“åº”
            total_time = time.time() - request_start
            content_chunks = sum(1 for chunk in [True] if full_response)  # ç®€åŒ–è®¡ç®—
            logger.bind(tag=TAG).info(f"å‡½æ•°è°ƒç”¨ç»Ÿè®¡ - æ€»chunkæ•°: {chunk_count}, æ€»è€—æ—¶: {total_time:.3f}s, å¹³å‡æ¯chunk: {total_time/chunk_count*1000:.1f}ms")
            logger.bind(tag=TAG).info(f"LLMå‡½æ•°è°ƒç”¨å®Œæ•´å“åº”: {full_response}")
            if function_calls:
                logger.bind(tag=TAG).info(f"LLMå‡½æ•°è°ƒç”¨ä¿¡æ¯: {function_calls}")

        except Exception as e:
            logger.bind(tag=TAG).error(f"Error in function call streaming: {e}")
            yield f"ã€OpenAIæœåŠ¡å“åº”å¼‚å¸¸: {e}ã€‘", None
